"""
AI Consensus Engine for trading analysis.
Integrates Qwen3-Max and DeepSeek-V3.2 for 2-model consensus.
"""

import asyncio
import openai
from typing import Dict, Any, Optional, List
from decimal import Decimal
from src.config import get_settings, LEVERAGE_TRADING_SYSTEM_PROMPT, build_analysis_prompt
from src.utils import setup_logging, parse_ai_response
from src.database import get_db_client
from src.redis_client import get_redis_client
import json

logger = setup_logging()


class AIConsensusEngine:
    """Multi-model AI consensus engine for trading decisions."""

    def __init__(self):
        self.settings = get_settings()

        # Initialize AI clients
        # Qwen3-Max via OpenRouter (OpenAI-compatible API)
        self.qwen_client = openai.AsyncOpenAI(
            api_key=self.settings.openrouter_api_key,
            base_url="https://openrouter.ai/api/v1"
        )

        # DeepSeek uses OpenAI-compatible API
        self.deepseek_client = openai.AsyncOpenAI(
            api_key=self.settings.deepseek_api_key,
            base_url="https://api.deepseek.com"
        )

    async def _analyze_with_retry(self, analyze_func, symbol: str, market_data: Dict[str, Any], model_name: str, max_retries: int = 3) -> Optional[Dict[str, Any]]:
        """
        Retry wrapper for AI analysis with exponential backoff.

        Args:
            analyze_func: The analysis function to call
            symbol: Trading symbol
            market_data: Market data
            model_name: Name of the AI model for logging
            max_retries: Maximum number of retry attempts

        Returns:
            Analysis result or None if all attempts fail
        """
        for attempt in range(max_retries):
            try:
                result = await asyncio.wait_for(
                    analyze_func(symbol, market_data),
                    timeout=self.settings.ai_timeout_seconds
                )
                if result:
                    return result
            except asyncio.TimeoutError:
                logger.warning(f"{model_name} timeout on attempt {attempt + 1}/{max_retries}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(2 ** attempt)  # Exponential backoff
            except Exception as e:
                logger.error(f"{model_name} error on attempt {attempt + 1}/{max_retries}: {e}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(2 ** attempt)

        logger.error(f"{model_name} failed after {max_retries} attempts")
        return None

    async def get_individual_analyses(self, symbol: str, market_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Get individual analyses from DeepSeek model.
        (Qwen3-Max disabled due to API key issues)

        Args:
            symbol: Trading symbol
            market_data: Market data dict with price, indicators, etc.

        Returns:
            List of individual analyses (currently just DeepSeek)
        """
        logger.info(f"Requesting AI analysis for {symbol} (DeepSeek only)...")

        # Get analysis from DeepSeek only
        analysis = await self._analyze_with_retry(
            self._analyze_with_deepseek,
            symbol,
            market_data,
            "DeepSeek-V3.2"
        )

        # Handle failures gracefully
        valid_analyses = []
        if analysis is not None:
            valid_analyses.append(analysis)
        else:
            logger.error(f"DeepSeek analysis failed for {symbol}")

        logger.info(f"Got {len(valid_analyses)}/1 analyses for {symbol}")
        return valid_analyses

    async def get_consensus(self, symbol: str, market_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Get AI consensus - require at least 2 out of 3 models to agree.
        Implements retry logic and graceful degradation.

        Args:
            symbol: Trading symbol
            market_data: Market data dict with price, indicators, etc.

        Returns:
            Consensus analysis with action, confidence, and reasoning
        """
        # Check Redis cache first (much faster than PostgreSQL)
        redis = await get_redis_client()
        cached = await redis.get_cached_ai_analysis(symbol, '5m')

        if cached:
            logger.debug(f"âœ… Using cached AI analysis for {symbol} (from Redis)")
            return cached

        # Get analysis from DeepSeek only (Qwen3-Max disabled)
        logger.info(f"Requesting AI analysis for {symbol} (DeepSeek only)...")

        analysis = await self._analyze_with_retry(
            self._analyze_with_deepseek,
            symbol,
            market_data,
            "DeepSeek-V3.2"
        )

        # Handle failure
        if analysis is None:
            logger.warning(f"DeepSeek failed for {symbol}")
            return {
                'action': 'hold',
                'side': None,
                'confidence': 0.0,
                'consensus': False,
                'consensus_count': 0,
                'reason': 'AI analysis failed',
                'suggested_leverage': 2,
                'stop_loss_percent': 7.0,
                'risk_reward_ratio': 0.0,
                'reasoning': 'DeepSeek API unavailable',
                'models_used': []
            }

        # Single model - use its values directly
        consensus = {
            'action': analysis.get('action', 'hold'),
            'side': analysis.get('side'),
            'confidence': round(analysis.get('confidence', 0), 2),
            'consensus': True,  # Single model always "agrees" with itself
            'consensus_count': 1,
            'suggested_leverage': max(2, min(5, analysis.get('suggested_leverage', 3))),
            'stop_loss_percent': max(5.0, min(10.0, analysis.get('stop_loss_percent', 7.0))),
            'risk_reward_ratio': round(analysis.get('risk_reward_ratio', 0), 2),
            'reasoning': analysis.get('reasoning', 'N/A'),
            'models_used': ['deepseek'],
            'individual_analyses': [analysis]
        }

        # Cache result in Redis (fast access for next 5 minutes)
        redis = await get_redis_client()
        await redis.cache_ai_analysis(
            symbol, '5m', consensus,
            self.settings.ai_cache_ttl_seconds
        )

        # Also cache in database for analysis/debugging
        db = await get_db_client()
        try:
            await db.set_ai_cache(
                symbol, 'consensus', '5m', consensus,
                self.settings.ai_cache_ttl_seconds
            )
        except Exception as e:
            logger.warning(f"Failed to cache in DB (non-critical): {e}")

        logger.info(
            f"AI Consensus for {symbol}: {consensus_action.upper()} "
            f"(confidence: {avg_confidence:.1%}, models: {len(agreeing_models)})"
        )

        return consensus

    async def _analyze_with_qwen(self, symbol: str, market_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Get analysis from Qwen3-Max via OpenRouter."""
        try:
            prompt = build_analysis_prompt(symbol, market_data)

            response = await self.qwen_client.chat.completions.create(
                model="qwen/qwen3-max",  # OpenRouter model identifier
                messages=[
                    {"role": "system", "content": LEVERAGE_TRADING_SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=2048
            )

            content = response.choices[0].message.content
            analysis = parse_ai_response(content)

            if analysis:
                analysis['model_name'] = 'qwen3-max'
                logger.debug(f"Qwen3-Max analysis: {analysis.get('action')} ({analysis.get('confidence', 0):.0%})")
                return analysis
            else:
                logger.warning("Failed to parse Qwen3-Max response")
                return None

        except Exception as e:
            logger.error(f"Qwen3-Max API error: {e}")
            raise

    async def _analyze_with_deepseek(self, symbol: str, market_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Get analysis from DeepSeek V3."""
        try:
            prompt = build_analysis_prompt(symbol, market_data)

            response = await self.deepseek_client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": LEVERAGE_TRADING_SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=2048
            )

            content = response.choices[0].message.content
            analysis = parse_ai_response(content)

            if analysis:
                analysis['model_name'] = 'deepseek'
                logger.debug(f"DeepSeek analysis: {analysis.get('action')} ({analysis.get('confidence', 0):.0%})")
                return analysis
            else:
                logger.warning("Failed to parse DeepSeek response")
                return None

        except Exception as e:
            logger.error(f"DeepSeek API error: {e}")
            raise

    async def get_exit_signal(
        self,
        symbol: str,
        market_data: Dict[str, Any],
        position: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Get AI recommendation for exiting an existing position.
        Uses faster, cheaper model (DeepSeek) for position monitoring.

        Returns:
            Dict with 'should_exit', 'reason', 'confidence'
        """
        try:
            # Build exit analysis prompt
            prompt = f"""You are monitoring an open {position['side']} position for {symbol}.

POSITION DETAILS:
Entry Price: ${position['entry_price']:.4f}
Current Price: ${market_data['current_price']:.4f}
Leverage: {position['leverage']}x
Unrealized P&L: ${position.get('unrealized_pnl_usd', 0):.2f}
Stop-Loss: ${position['stop_loss_price']:.4f}
Time in Position: {position.get('duration', 'unknown')}

CURRENT MARKET DATA:
RSI (15m): {market_data['indicators']['15m']['rsi']:.1f}
MACD: {market_data['indicators']['15m']['macd']:.4f}
Market Regime: {market_data['market_regime']}

Should we exit this position now, or continue holding?

RESPONSE FORMAT (JSON only):
{{
    "should_exit": true|false,
    "confidence": 0.0-1.0,
    "reason": "brief explanation"
}}"""

            # Use DeepSeek for cost efficiency
            response = await self.deepseek_client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": "You are a professional trader monitoring positions. Be conservative - only recommend exit if there's clear reason."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=512
            )

            content = response.choices[0].message.content
            result = parse_ai_response(content)

            if result:
                return result
            else:
                return {'should_exit': False, 'confidence': 0.0, 'reason': 'Failed to parse AI response'}

        except Exception as e:
            logger.error(f"Error getting exit signal: {e}")
            return {'should_exit': False, 'confidence': 0.0, 'reason': f'API error: {e}'}


# Singleton instance
_ai_engine: Optional[AIConsensusEngine] = None


def get_ai_engine() -> AIConsensusEngine:
    """Get or create AI engine instance."""
    global _ai_engine
    if _ai_engine is None:
        _ai_engine = AIConsensusEngine()
    return _ai_engine
